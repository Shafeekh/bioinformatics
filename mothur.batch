###################################################################
###################################################################
###################################################################


##Basic mothur processing of MiSeq sequences using the Caporasso/Kozich primers.  This batch is based on mothur.org/wiki/MiSeq_SOP  All commands are explained in much more detail in that SOP. If your data is not demultiplexed, see the chunk of code at the bottom of this file.
##I use a computer with a high memory node (256gb RAM) with 16 processors. You'll need to adjust processors used to match your system. 


#############
##### I've started using basemount to download the fastq directly to the server. This will download and rename the files to include sample name and sample ID.
#p=PROJECTNAME
#mkdir -p $p/fastq
#for f in basespace/Projects/$p/Samples/*/Files/*.gz; 
#do s=${f##basespace/Projects/$p/Samples/}; s=${s%%/*}; 
#cp $f $p"/fastq/"$s"."${f##*Files/}; 
#done
#####################

### In addition to your sequence files and the oligos file, you need some files from the mothur website to be accessible (either in your path or in the folder you are working in). The line below moves them from my public directory on the BBC server to your current directory.
##############silva.v4.fasta (which was created from silva.bacteria.fasta), trainset10_082014.pds.fasta, trainset10_082014.pds.tax
#system(cp /scratch/km/mothur.files/* .)



### Currently Mothur 1.35 needs uncompressed fastq run
###this has been fixed in 1.36 IF you compiled with Boost
#system(gzip -d fastq/*001.fastq.gz)

#make.file(inputdir=fastq)


make.contigs(processors=16, file=YOURFILES.file)
#####


#Summary.seqs counts the number of sequences you are currently dealing with, running this after every step gives you a good starting point for troubleshooting if the process fails or if it produces something other than what you expect.
summary.seqs(fasta=current)

#Cleaning up obviously bad sequences
screen.seqs(fasta=current, group=current, summary=current, maxambig=0, maxlength=275)

summary.seqs(fasta=current)

#reduce fasta size by only keeping one of each sequence, this generates a names file
unique.seqs(fasta=current)

summary.seqs(fasta=current, name=current)

#replaces both the names and group file (which contain the name of every sequence) with a count table
count.seqs(name=current, group=current)

#align to a custom silva db that was trimmed to v4 using "pcr.seqs(fasta=silva.nr_119.fasta, start=13862, end=23444, keepdots=F)"
align.seqs(fasta=current, reference=silva.nr_v119.v4.align)

summary.seqs(fasta=current, count=current)

#remove the seqs that just didn't align (using the nubmers from the previous summmary.seqs
screen.seqs(fasta=current, count=current, summary=current, start=1968, end=11550, maxhomop=8)

#remove columns from alignment that only contain -
filter.seqs(fasta=current, vertical=T)

summary.seqs(fasta=current, count=current)

#pre.cluster to 1% difference to reduce computation time
pre.cluster(fasta=current, diffs=2, count=current)

summary.seqs(fasta=current, count=current)

#calls chimeras only from the samples that they are called chimeras, if you want to remove from all samples change dereplicate=f
chimera.uchime(fasta=current, count=current, dereplicate=t)

#removes chimeras
remove.seqs(fasta=current, accnos=current, count=current)

summary.seqs(fasta=current, count=current)

#RDP classifier using silva as the reference (similar results as RDP reference but some are classified to species)
classify.seqs(fasta=current, count=current, reference=silva.nr_v119.v4.align, taxonomy=silva.nr_v119.tax, cutoff=80)

#remove all non-target sequences
remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Archaea-Eukaryota)

#make tax.summary file for krona that doesn't have above taxon
summary.tax(taxonomy=current, count=current)

###### changing clustering to opti method with 1.39
#make otus for each Order individually, for very large datasets (hundreds of samples) you may need to decrease the taxlevel to 5 or even 6. If you use 6 you will likely only get 3% OTUs because the within group differences aren't always 5%
#cluster.split(fasta=current, count=current, taxonomy=current, splitmethod=classify, taxlevel=4, cutoff=0.15, processors=16, cluster=f)
#if your data is very diverse you may end up with .dist files that are too large for the number of processers (if you are using 4 processors your dist file needs to fit in RAM 4 times. For my system, I have to drop the processors in this step if my largest .dist is over 64GB)
#cluster.split(file=current, processors=4)

dist.seqs(fasta=current, countends=F, cutoff= 0.03, processors=16)

cluster(column=current, count=current, method=opti)


summary.seqs(processors=16)

#make 3, 5 and 10% OTU matrix #### as of 1.39 can only do one level at a time
#make.shared(list=current, count=current, label=0.03-0.05-0.10)
make.shared(list=current, count=current)

#classify each OTU, used the RDP classification 100% means all seqs in that OTU match at that classification level
classify.otu(list=current, count=current, taxonomy=current)

get.oturep(fasta=current, count=current, list=current, method=abundance)

#check number of sequences in each sample
count.groups(shared=current)

#alpha diversity
summary.single(shared=current, calc=nseqs-sobs-coverage-shannon-shannoneven-invsimpson, subsample=10000)

#beta diversity
dist.shared(shared=current, calc=braycurtis-jest-thetayc, subsample=10000)

#make a rarefied OTU table for heatmaps, indicator species, etc
sub.sample(shared=current, size=10000)
 
#make rarified taxonomy file for krona
sub.sample(taxonomy=current, count=current, list=current, size=10000, persample=true, label=0.03)
summary.tax(taxonomy=current, count=current)

system(mkdir send)
system(cp *shared send)
system(cp *cons.tax* send)
system(cp *pick.tax.summary send)
system(cp *.rep.fasta send)
system(cp *lt.ave.dist send)
system(cp *groups.ave-std.summary send)
system(cp mothur.batch send)
system(cp mothur.*.logfile send)
system(rm send/*0.01*)
system(rm send/*0.02*)
system(rm send/*0.04*)
system(rm send/*0.06*)
system(rm send/*0.07*)
system(rm send/*0.08*)
system(rm send/*0.09*)
system(rm send/*0.11*)
system(rm send/*0.12*)
system(rm send/*0.13*)
system(rm send/*0.14*)

###############
## Krona
#python mothur_krona_XML.py /path/to/*nr_v119_wang.pick.tax.summary >output.xml
#ktImportXML output.xml


##################################################################
######### Running mothur with non-demultiplexed samples  #########
##################################################################
### Originally I wrote this batch file for one MiSeq run of non-demultiplexed data, here's my sage advice for that situation.  If you have multiple runs that weren't demultiplexed by the MiSeq, you will need to run this process in 2 steps:  First make.contigs on each run individually (if you're feeling sassy you can do this with a "for n in" statement which I haven't provided) then combine all the *001.trim.contigs.fasta and *.contigs.groups

###################################################################
###################################################################
############################
##Run these steps in shell, cd into downloaded project folder
#mkdir fastq
###########
####### Sept 2016 Illumina changed their folder structure
#for i in */*.gz; do cp $i "fastq""/"${i%%-*}"."`basename $i`; done
#### older structure
#for i in */Data/Intensities/BaseCalls/*.gz; do mv $i "fastq""/"${i%%-*}"."`basename $i`; done
###########
#mothur "#make.file(inputdir=fastq, type=gz)"
## add the user name as the first column for the files.file, this worked for 1.36, doesn't seem necessary for 1.38 BUT mothur has started assuming certain characters will be absent in your sample names so you must check the files file
#awk -F'[/_]' '{printf "%s\t%s\n", $2, $0}' fastq/stability.files > YOURFILES.file
#cp /scratch/km/mothur.files/* .
############################

## Running single non-demultiplexed samples
# replace YOUR with the names of your files, also make sure that you change the processors if you are working on a personal computer rather than server
#make.contigs(processors=16, ffastq=YOUR_R1_001.fastq, rfastq=YOUR_R2_001.FASTQ, findex=YOUR_I_001.FASTQ, oligos=YOUR.OLIGOS)

########################
### This section can be ignored if you are analyzing a single MiSeq run
### When combining multiple sequencing runs, you have to run make.contigs on each run individually.
###
### This for loop will work for samples where the files are names like
###		9_2_14_Undetermined_S0_L001_R1_001.fastq
###		9_2_14_Undetermined_S0_L001_R2_001.fastq
###		9_2_14_Undetermined_S0_L001_I1_001.fastq
###		9_2_14.oligos
###
#for o in *.oligos; do 
#		i=`basename $o .oligos`_Undetermined_S0_L001_I1_001.fastq; 
#		f=`basename $o .oligos`_Undetermined_S0_L001_R1_001.fastq; 
#		r=`basename $o .oligos`_Undetermined_S0_L001_R2_001.fastq; 
#		mothur "#make.contigs(processors=16, ffastq=$f, rfastq=$r, findex=$i, oligos=$o)"; 
#	done
###
### Then concatenate the contigs fasta and groups, the following commands will concatenate all the 
### *001.trim.contigs.fasta and *.contigs.groups in your current directory.  
### MAKE SURE THIS IS WHAT YOU WANT TO DO, that you really want to analyze all of the fasta together.  
### Uncomment the following 4 lines and change NAME to something that is useful and memorable to you.
#
#system(cat /archive/kmaas/*001.trim.contigs.fasta > /common/scratch/km/YOUR.contigs.fasta)
#system(cat /archive/kmaas/*contigs.groups > /common/scratch/km/YOUR.contigs.groups)
#summary.seqs(fasta=YOUR.contigs.fasta)
#screen.seqs(fasta=current, group=YOUR.contigs.groups, summary=current, maxambig=0, maxlength=275)
#
### If you are combining runs, comment out the "make.contigs" line above and the next 2 lines because you just ran them
###################################################################
############ End non-demultiplexed section ########################
###################################################################
